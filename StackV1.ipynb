{
 "metadata": {
  "name": "",
  "signature": "sha256:f01326797d593b0bdf5b7df56d4d30ea6f7dc817c29d03459156e142b3273c9c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Stick with current features, add a few classifiers and stack with linear regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn import preprocessing, ensemble, cross_validation, grid_search\n",
      "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn import cross_validation, svm\n",
      "from sklearn.linear_model import LinearRegression, BayesianRidge, SGDRegressor\n",
      "import xgboost as xgb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print os.listdir('.')\n",
      "directory = os.path.join(os.getcwd(),'competition_data')\n",
      "filename = 'train_set.csv'\n",
      "path = os.path.join(directory,filename)\n",
      "print path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['.ipynb_checkpoints', 'benchmark.csv', 'competition_data', 'Feat2OheXgb.ipynb', 'Feat2wXGB.ipynb', 'Feat3wXGB.ipynb', 'MoreFeatures.ipynb', 'MoreFeatures2.ipynb', 'MoreFeatureswXgb.ipynb', 'Prelim.ipynb', 'StackV1.ipynb']\n",
        "C:\\Users\\Victor\\Desktop\\Kaggle\\Caterpillar\\competition_data\\train_set.csv\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv(os.path.join(directory,'train_set.csv'), parse_dates=[2,])\n",
      "test = pd.read_csv(os.path.join(directory,'test_set.csv'), parse_dates=[3,])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tubes = pd.read_csv(os.path.join(directory,'tube.csv'))\n",
      "\n",
      "train = pd.merge(train,tubes,on='tube_assembly_id',how='inner')\n",
      "test = pd.merge(test,tubes,on='tube_assembly_id',how='inner')\n",
      "\n",
      "train['material_id'].fillna('SP-9999',inplace=True)\n",
      "test['material_id'].fillna('SP-9999',inplace=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Featurizing Bill of Materials "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "materials = pd.read_csv(os.path.join(directory,'bill_of_materials_with_labels.csv'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "materials.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "Index([u'tube_assembly_id', u'component_id', u'label'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "comp_filenames = ['comp_adaptor.csv',\n",
      "              'comp_boss.csv',\n",
      "              'comp_elbow.csv',\n",
      "              'comp_float.csv',\n",
      "              'comp_hfl.csv',\n",
      "              'comp_nut.csv',\n",
      "              'comp_other.csv',\n",
      "              'comp_sleeve.csv',\n",
      "              'comp_straight.csv',\n",
      "              'comp_tee.csv',\n",
      "              'comp_threaded.csv']\n",
      "\n",
      "comp_files = [pd.read_csv(os.path.join(directory,filename)) for filename in comp_filenames]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"filename = 'comp_adaptor.csv'\n",
      "filtered_materials = materials[materials['label']==6].drop('label',1)\n",
      "comp_file = pd.read_csv(os.path.join(directory,filename)\n",
      "pd.merge(filtered_materials,comp_file,on='component_id', how='inner').shape[0]\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "\"filename = 'comp_adaptor.csv'\\nfiltered_materials = materials[materials['label']==6].drop('label',1)\\ncomp_file = pd.read_csv(os.path.join(directory,filename)\\npd.merge(filtered_materials,comp_file,on='component_id', how='inner').shape[0]\""
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(1,7):\n",
      "    #filter by instances\n",
      "    filtered_materials = materials[materials['label']==i].drop('label',1)\n",
      "    for comp_file in comp_files:\n",
      "        #join by component type files\n",
      "        mat_comp = pd.merge(filtered_materials,comp_file,on='component_id', how='inner')\n",
      "        #join onto train and test sets\n",
      "        if mat_comp.shape[0]!=0:\n",
      "            train = pd.merge(train,mat_comp,on='tube_assembly_id', how='left')\n",
      "            test = pd.merge(test,mat_comp,on='tube_assembly_id', how='left')\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(30213, 440)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train.fillna(0,inplace=True)\n",
      "test.fillna(0,inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "End Bill of Materials stuff"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# drop useless columns and create labels\n",
      "idx = test.id.values.astype(int)\n",
      "test = test.drop(['id', 'tube_assembly_id', 'quote_date'], axis = 1)\n",
      "labels = train.cost.values\n",
      "train = train.drop(['quote_date', 'cost', 'tube_assembly_id'], axis = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert data to numpy array\n",
      "train = np.array(train)\n",
      "test = np.array(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rangeset = train.shape[1]\n",
      "for i in range(rangeset):\n",
      "    #if type(sorted(train[:,i],reverse=True)[1]) is str:\n",
      "    if any(type(x) is str for x in train[:,i]) or any(type(x) is str for x in test[:,i]):\n",
      "        train[:,i][train[:,i]==0] = 'zzz'\n",
      "        test[:,i][test[:,i]==0] = 'zzz'\n",
      "        lbl = preprocessing.LabelEncoder()\n",
      "        lbl.fit(list(train[:,i]) + list(test[:,i]))\n",
      "        train[:,i] = lbl.transform(train[:,i])\n",
      "        test[:,i] = lbl.transform(test[:,i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# object array to float\n",
      "train = train.astype(float)\n",
      "test = test.astype(float)\n",
      "\n",
      "# i like to train on log(1+x) for RMSLE ;) \n",
      "# The choice is yours :)\n",
      "label_log = np.log1p(labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classifier section"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(train, label_log, test_size = 0.2, random_state = 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#RMSLE error function\n",
      "import math\n",
      "\n",
      "#A function to calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
      "def rmsle(y, y_pred):\n",
      "\tassert len(y) == len(y_pred)\n",
      "\tterms_to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
      "\treturn (sum(terms_to_sum) * (1.0/len(y))) ** 0.5\n",
      "\n",
      "from sklearn.metrics import make_scorer\n",
      "\n",
      "custom_score = make_scorer(rmsle,False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testRun = 'No'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sci-kit random forests\n",
      "\n",
      "parameters = {'n_estimators': [1000] }\n",
      "\n",
      "model_rfr = RandomForestRegressor(n_estimators=100)\n",
      "\n",
      "if testRun == 'Yes':\n",
      "    model_rfr.fit(X_train, y_train)\n",
      "else:\n",
      "    model_rfr.fit(train,label_log)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if testRun == 'Yes':\n",
      "    val_preds_rfr = np.expm1(model_rfr.predict(X_test))\n",
      "    norm_labels = np.expm1(y_test)\n",
      "    score_val_rfr = rmsle(norm_labels,val_preds_rfr)\n",
      "    print 'Base score is 0.249'\n",
      "    print score_val_rfr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# xgboost random forest model\n",
      "\n",
      "params = {}\n",
      "params[\"objective\"] = \"reg:linear\"\n",
      "params[\"eta\"] = 0.1\n",
      "params[\"min_child_weight\"] = 5\n",
      "params[\"subsample\"] = 1.0\n",
      "params[\"scale_pos_weight\"] = 1.0\n",
      "params[\"silent\"] = 1\n",
      "params[\"max_depth\"] = 7\n",
      "\n",
      "plst = list(params.items())\n",
      "\n",
      "if testRun == 'Yes':\n",
      "    xgtrain = xgb.DMatrix(X_train, label = y_train)\n",
      "    xgtest = xgb.DMatrix(X_test)\n",
      "else:\n",
      "    xgtrain = xgb.DMatrix(train, label=label_log)\n",
      "    xgtest = xgb.DMatrix(test)\n",
      "\n",
      "num_rounds = 500\n",
      "model_xgb = xgb.train(plst, xgtrain, num_rounds)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if testRun == 'Yes':\n",
      "    val_preds_xgb = np.expm1(model_xgb.predict(xgtest))\n",
      "    norm_labels = np.expm1(y_test)\n",
      "    score_val_xgb = rmsle(norm_labels,val_preds_xgb)\n",
      "    print 'Base score is 0.207'\n",
      "    print score_val_xgb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_gbr = GradientBoostingRegressor()\n",
      "\n",
      "if testRun == 'Yes':\n",
      "    model_gbr.fit(X_train, y_train)\n",
      "else:\n",
      "    model_gbr.fit(train,label_log)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if testRun == 'Yes':\n",
      "    val_preds_gbr = np.expm1(model_gbr.predict(X_test))\n",
      "    norm_labels = np.expm1(y_test)\n",
      "    score_val_gbr = rmsle(norm_labels,val_preds_gbr)\n",
      "    print 'Base score is 0.327'\n",
      "    print score_val_gbr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if testRun == 'Yes':\n",
      "    X_stack_train = [list(t) for t in zip(model_rfr.predict(X_train),model_xgb.predict(xgtrain),model_gbr.predict(X_train))]\n",
      "    X_stack_test = [list(t) for t in zip(model_rfr.predict(X_test),model_xgb.predict(xgtest),model_gbr.predict(X_test))]\n",
      "else:\n",
      "    X_stack_train = [list(t) for t in zip(model_rfr.predict(train),model_xgb.predict(xgtrain),model_gbr.predict(train))]\n",
      "    X_stack_test = [list(t) for t in zip(model_rfr.predict(test),model_xgb.predict(xgtest),model_gbr.predict(test))] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_stack = LinearRegression()\n",
      "\n",
      "if testRun == 'Yes':\n",
      "    model_stack.fit(X_stack_train,y_train)\n",
      "else:\n",
      "    model_stack.fit(X_stack_train,label_log)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if testRun == 'Yes':\n",
      "    val_preds_stack = np.expm1(model_stack.predict(X_stack_test))\n",
      "    norm_labels = np.expm1(y_test)\n",
      "    score_val_stack = rmsle(norm_labels,val_preds_stack)\n",
      "    print 'Base score is 0.237'\n",
      "    print score_val_stack"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if testRun == 'No':\n",
      "    preds = np.expm1(model_stack.predict(X_stack_test))\n",
      "    preds = pd.DataFrame({\"id\": idx, \"cost\": preds})\n",
      "    preds.to_csv('benchmark.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Looking into the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An analysis into the relationships between the different data files:\n",
      "\n",
      "test_set is root\n",
      "\n",
      "*sheets with tube assembly ids*:  \n",
      "bill_of_materials; components for every tube assembly  \n",
      "specs; specifications for every tube assembly  \n",
      "tube; description for every tube, including spec id, size and bend information, end of tube info  \n",
      "\n",
      "\n",
      "\n",
      "*sheets without tube assembly ids with component ids*:\n",
      "* components; component type list summary \n",
      "\n",
      "comp_adaptor;  detailed component specs, adaptor type  \n",
      "comp_boss; detailed component specs, boss type  \n",
      "comp_elbow; detailed component specs, elbow type  \n",
      "comp_float; detailed component specs, float type  \n",
      "comp_hfl; detailed component specs, hfl type  \n",
      "comp_nut; detailed component specs, nut type  \n",
      "comp_other; detailed component specs, other type  \n",
      "comp_sleeve; detailed component specs, sleeve type  \n",
      "comp_straight; detailed component specs, straight type  \n",
      "comp_tee; detailed component specs, tee type  \n",
      "comp_threaded; detailed component specs, threaded type  \n",
      "\n",
      "\n",
      "*sheets without tube assembly ids with other ids*  \n",
      "tube_end_form; end of tube types, yes/no on forming  \n",
      "type_component; component type id with name  \n",
      "type_connection; connection type id (in some components) with name  \n",
      "type_end_form; end form id (in some components) with name  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}